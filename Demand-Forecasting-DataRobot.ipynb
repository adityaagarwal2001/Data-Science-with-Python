{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Eggs Item Sales Forecast Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "from covid19dh import covid19\n",
    "import dagstermill as dm\n",
    "from dagster import ExpectationResult, EventMetadataEntry\n",
    "import datarobot as dr\n",
    "from datarobot import Project, Deployment\n",
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sched, time\n",
    "import seaborn as sns\n",
    "import snowflake.connector\n",
    "import statsmodels as sm\n",
    "import urllib.request\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataRobot API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAROBOT_ENDPOINT = os.environ[\"DATAROBOT_ENDPOINT\"]\n",
    "DATAROBOT_API_TOKEN = os.environ[\"DATAROBOT_API_TOKEN\"]\n",
    "\n",
    "try:\n",
    "    dr.Client(token=DATAROBOT_API_TOKEN,\n",
    "              endpoint=DATAROBOT_ENDPOINT)\n",
    "    dr_available = True\n",
    "except:\n",
    "    dr_available = False\n",
    "\n",
    "dr_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_list = dr.Project.list(search_params={'project_name': 'item_forecast'})\n",
    "except:\n",
    "    project_list = None\n",
    "project_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_names = [x.project_name for x in project_list]\n",
    "except:\n",
    "    project_names = []\n",
    "project_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_retained_projects = 5\n",
    "num_retained_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_sorted = sorted(project_names, reverse=True)\n",
    "projects_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_most_recent = dr.Project(projects_sorted[0])\n",
    "except:\n",
    "    project_most_recent = None\n",
    "project_most_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_to_delete = projects_sorted[num_retained_projects:]\n",
    "projects_to_delete"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for p in projects_to_delete:\n",
    "    dr.Project(p).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get initial dataset from Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "SNOWFLAKE_USER = os.environ[\"SNOWFLAKE_USER\"]\n",
    "SNOWFLAKE_PASSWORD = os.environ[\"SNOWFLAKE_PASSWORD\"]\n",
    "SNOWFLAKE_ACCOUNT = os.environ[\"SNOWFLAKE_ACCOUNT\"]\n",
    "\n",
    "\n",
    "with snowflake.connector.connect(user=SNOWFLAKE_USER, password=SNOWFLAKE_PASSWORD, account=SNOWFLAKE_ACCOUNT) as conn:\n",
    "    items = conn.cursor().execute(\"SELECT * FROM models.data_science.data_science_items_batch_temperature where calendar_date < current_date()\").fetch_pandas_all()\n",
    "    df_calendar = conn.cursor().execute(\"SELECT calendar_date, holiday, closed FROM models.goodeggs.calendar\").fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.columns = map(str.lower, items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up holiday and closed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.sort_values(by=['calendar_date', 'batch', 'temperature_zone'], ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out floral and virtual zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items['temperature_zone'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = ['floral', 'flowers', 'virtual']\n",
    "exclude_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items[~items.temperature_zone.isin(exclude_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and Temperature Zone Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(items['batch'].unique())\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_temp_zones = len(items['temperature_zone'].unique())\n",
    "n_temp_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.columns = map(str.lower, df_calendar.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.sort_values(by=['calendar_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = df_calendar[['calendar_date', 'holiday', 'closed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID-19 Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://covid19datahub.io/articles/api/python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid, _ = covid19(\"USA\", level = 2, start = datetime.date(2020, 1, 1), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid[df_covid['administrative_area_level_2'] == 'California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_covid[['date', 'confirmed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases['count'] = df_cases['confirmed'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases['date'] = df_cases['date'].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join sales, calendar, and COVID-19 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['date'] = items['calendar_date'].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(columns=['calendar_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar['date'] = df_calendar['calendar_date'].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.drop(columns=['calendar_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc = pd.merge(items, df_calendar, left_on='date', right_on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_sc, df_cases, left_on='date', right_on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['date', 'batch', 'confirmed'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataRobot Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and Calendar Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_start_date = None\n",
    "holdout_duration = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advance_vars = ['holiday', 'closed']\n",
    "feature_settings = []\n",
    "for av in advance_vars:\n",
    "    feature_settings.append(dr.FeatureSettings(av,\n",
    "                                               known_in_advance=True,\n",
    "                                               do_not_derive=False))\n",
    "feature_settings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dr.CalendarFile.get_allowed_country_codes()#[0]['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_code = dr.CalendarFile.get_allowed_country_codes()[0]['code']\n",
    "calendar = dr.CalendarFile.create_calendar_from_country_code('US', \"2017-01-01\", \"2021-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Time Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_per_day = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_days = 14\n",
    "derivation_window = derivation_days * hours_per_day\n",
    "derivation_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_days = 21\n",
    "forecast_window = forecast_days * hours_per_day\n",
    "forecast_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_partition = dr.DatetimePartitioningSpecification(\n",
    "    use_time_series                 = True,\n",
    "    datetime_partition_column       = 'datetime',\n",
    "    multiseries_id_columns          = ['temperature_zone'],\n",
    "    feature_derivation_window_start = -derivation_window,\n",
    "    feature_derivation_window_end   = 0,\n",
    "    forecast_window_start           = 8,\n",
    "    forecast_window_end             = forecast_window,\n",
    "    feature_settings                = feature_settings,\n",
    "#     calendar_id                     = calendar.id\n",
    ")\n",
    "time_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every week, we create a new project because of the updated dataset (the new week of data for augmentation. DataRobot retrains on the updated dataset and returns the best model according to the leaderboard. We then make a 21-day forecast and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_today = datetime.date.today().strftime('%Y%m%d')\n",
    "date_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_datetime = datetime.datetime.now().strftime('%Y%m%d%H%M')\n",
    "run_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = '_'.join(['item_forecast', run_datetime])\n",
    "project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = None\n",
    "\n",
    "if dr_available:\n",
    "    try:\n",
    "        project = dr.Project.create(\n",
    "            project_name = project_name, \n",
    "            sourcedata   = df_train\n",
    "        )\n",
    "        project_created = True\n",
    "    except:\n",
    "        project_created = False\n",
    "\n",
    "project_created, project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start AutoPilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "if project_created:\n",
    "\n",
    "    project.set_target(\n",
    "            target              = 'qty_sold',      \n",
    "            mode                = dr.AUTOPILOT_MODE.QUICK , # dr.AUTOPILOT_MODE.FULL_AUTO,\n",
    "            partitioning_method = time_partition,\n",
    "            metric              = 'SMAPE',\n",
    "            worker_count        = -1                        # use all available workers\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autopilot_done = False\n",
    "\n",
    "start_time = time.time()\n",
    "while project_created and not autopilot_done:\n",
    "    current_time = time.time()\n",
    "    time.sleep(60.0 - ((current_time - start_time) % 60.0))\n",
    "    status = project.get_status()\n",
    "    autopilot_done = status['autopilot_done']\n",
    "    time_stamp = datetime.datetime.fromtimestamp(current_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # print(time_stamp, status)\n",
    "\n",
    "# autopilot_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autopilot_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Leaderboard\n",
    "\n",
    "If we successfully created a project with a new model, then select the best current model and get the predictions. If project creation failed, then fall back to the most recent model and make the predictions with that model. In either case, sort the models by best metric, e.g., lowest SMAPE. This code pulls the DR Blueprints with corresponding scores, then stores them in the Pandas dataframe named scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not project_created and project_most_recent:\n",
    "    project = project_most_recent\n",
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "scores = None\n",
    "\n",
    "models = []\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "lb = project.get_datetime_models()\n",
    "best_models = sorted(\n",
    "                    [model for model in lb if model.metrics[project.metric]['backtesting']],  \n",
    "                    key=lambda m: m.metrics[project.metric]['backtesting'],\n",
    "                    )\n",
    "\n",
    "for m in best_models:\n",
    "\n",
    "    backtest_scores = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                'project_name': project.project_name,\n",
    "                'project_id': project.id,\n",
    "                'model_id': m.id,\n",
    "                'model_type': m.model_type,\n",
    "                'feature_list': m.featurelist_name,\n",
    "                'optimization_metric': project.metric,\n",
    "                'scores': m.metrics,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    scores = scores.append(backtest_scores, sort=False).reset_index(drop=True)  \n",
    "\n",
    "\n",
    "scores = scores.join(pd.json_normalize(scores[\"scores\"].tolist())).drop(labels=['scores'], axis=1) \n",
    "\n",
    "# Drop Empty Columns\n",
    "scores = scores[scores.columns.drop(list(scores.filter(regex='crossValidation$')))]\n",
    "\n",
    "# Rename Columns\n",
    "scores.columns = scores.columns.str.replace(\".backtesting\", \"_all_bt\")\n",
    "scores.columns = scores.columns.str.replace(\".holdout\", \"_holdout\")\n",
    "scores.columns = scores.columns.str.replace(\".validation\", \"_bt_1\")\n",
    "scores.columns = scores.columns.str.replace(' ', '_')\n",
    "\n",
    "scores = scores[scores.columns.drop(list(scores.filter(regex='_All_BTScores$')))]\n",
    "\n",
    "# Filter down Accuracy Metrics \n",
    "dr_metrics = scores.filter(regex='SMAPE|RMSE').columns.to_list()\n",
    "dr_project = ['project_name', 'project_id', 'model_id', 'model_type', 'feature_list']\n",
    "dr_cols = dr_project + dr_metrics\n",
    "scores = scores[dr_cols]\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Best Model\n",
    "\n",
    "Get the best model based on the lowest SMAPE. We will make our predictions with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "\n",
    "smape = scores.loc[scores['SMAPE_all_bt'].notnull()]\n",
    "best_model = pd.DataFrame(smape.loc[smape.SMAPE_all_bt.idxmin()]).transpose()\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataRobot Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "project_id = best_model['project_id'].values[0]\n",
    "model_id = best_model['model_id'].values[0]\n",
    "project = dr.Project.get(project_id)\n",
    "model   = dr.Model.get(project_id, model_id)\n",
    "    \n",
    "project, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_rows = derivation_days * n_batches * n_temp_zones\n",
    "n_test_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_yesterday = (datetime.date.today() - datetime.timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "datetime_cutoff = ' '.join([date_yesterday, '16:00:00'])\n",
    "datetime_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_past = df_train[df_train['datetime'] <= datetime_cutoff].tail(n_test_rows).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_past.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_past.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_rows = forecast_days * n_batches * n_temp_zones\n",
    "n_future_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future = df_train.tail(n_future_rows).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future.loc[:, 'qty_sold'] = None\n",
    "dfp_future.loc[:, 'count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date_range = pd.date_range(start=date_today, periods=forecast_days * n_batches, freq='8H').repeat(n_temp_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future['datetime'] = forecast_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future['date'] = dfp_future['datetime'].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future.drop(columns=['holiday', 'closed'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future = pd.merge(dfp_future, df_calendar, left_on='date', right_on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_future.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine derivation and future frames for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.concat([dfp_past, dfp_future])\n",
    "dfp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_dr = project.upload_dataset(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_job = model.request_predictions(dataset_id = dfp_dr.id)\n",
    "predictions = pred_job.get_result_when_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['prediction'] = predictions['prediction'].round().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['timestamp', 'series_id', 'prediction']\n",
    "predictions = predictions[pred_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.rename(columns={\"timestamp\": \"calendar_date\", \"series_id\": \"temperature_zone\", \"prediction\": \"number_items_prediction\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Predictions\n",
    "\n",
    "The prediction dataframe will have 21 days of data with 4 predictions for each batch (3), so the total number of rows will be 21 x 4 x 3 = 252."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.yield_result(value=predictions, output_name=\"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "5cb66debf8efdc6e05d7e612bcd6aff43657137c73dca1d8f406635adb4758e7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
